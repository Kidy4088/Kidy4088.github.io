---
title: Hive DDL数据定义
date: 2021-02-24
tags:
  - Hive
categories:
  - 大数据
---

## 1. 创建数据库

1. 创建一个数据库，数据库在 HDFS 上的默认存储路径是/user/hive/warehouse/*.db。

```
hive (default)> create database db_hive;
```

2. 避免要创建的数据库已经存在错误，增加 if not exists 判断。（标准写法）

```
hive (default)> create database db_hive;
FAILED: Execution Error, return code 1 from 
org.apache.hadoop.hive.ql.exec.DDLTask. Database db_hive already 
exists
hive (default)> create database if not exists db_hive;
```

3. 创建一个数据库，指定数据库在 HDFS 上存放的位置

```
hive (default)> create database hive3 location '/hive3';
```

## 2. 查询数据库

### 2.1  显示数据库

1. 显示数据库

```
hive> show databases;
```

2. 过滤显示查询数据库

```
hive (default)> show databases like 'hive*';
OK
hive
hive2
```

### 2.2 查看数据库详情

1. 显示数据库信息

```
hive (default)> desc database default;
OK
db_name	comment	location	owner_name	owner_type	parameters
default	Default Hive database	hdfs://node-2:9000/user/hive/warehouse	public	ROLE
```

2. 显示数据库详细信息，extended

```
hive (default)> desc database extended default;
OK
db_name	comment	location	owner_name	owner_type	parameters
default	Default Hive database	hdfs://node-2:9000/user/hive/warehouse	public	ROLE
```

 ### 2.3 切换当前数据库

```
hive (default)> use default;
```

## 3. 修改数据库

用户可以使用 ALTER DATABASE 命令为某个数据库的 DBPROPERTIES 设置键-值对属性值，来描述这个数据库的属性信息。数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置。

```
hive (default)> alter database hive set dbproperties('createtime'='20200903');
OK
Time taken: 0.103 seconds
```

在 hive 中查看修改结果

```
hive (default)> desc database extended hive;
OK
db_name	comment	location	owner_name	owner_type	parameters
hive		hdfs://node-2:9000/user/hive/warehouse/hive.db	kidy	USER	{createtime=20200903}
```

## 4. 删除数据库

1. 删除空的数据库

```
drop database aa;
```

2. 如果删除的数据库不存在，最好采用 if exists 判断数据库是否存在

```
hive> drop database cc;
FAILED: SemanticException [Error 10072]: Database does not exist: 
db_hive
hive> drop database if exists cc;
```

3. 如果数据库不为空，可以采用 cascade 命令，强制删除

```
hive (default)> drop database momo;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. 
InvalidOperationException(message:Database momo is not empty. One or more tables exist.)
hive> drop database momo cascade;
```

## 5.创建表

1. 建表语法

```
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name
[(col_name data_type [COMMENT col_comment], ...)]
[COMMENT table_comment]
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
[CLUSTERED BY (col_name, col_name, ...)
[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
[ROW FORMAT row_format]
[STORED AS file_format]
[LOCATION hdfs_path]
```

2. 字段解释说明

- CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。
- EXTERNAL 关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION），Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。
- COMMENT 为表和列添加注释。
- PARTITIONED BY 创建分区表
- CLUSTERED BY 创建分桶表
- SORTED BY 不常用
- ROW FORMAT
  DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]
   [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] 
   | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]  
  用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive 通过 SerDe确定表的具体的列的数据。SerDe 是 Serialize/Deserilize 的简称，目的是用于序列化和反序列化。
- STORED AS 指定存储文件类型
  常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。
- LOCATION 指定表在 HDFS 上的存储位置。
- LIKE 允许用户复制现有的表结构，但是不复制数据。

